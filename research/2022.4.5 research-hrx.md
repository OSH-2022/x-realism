# 内存管理单元（MMU）相关调研

## 先问是什么

内存管理单元( MMU )，有时称为分页内存管理单元( PMMU )，是一种**计算机硬件单元**，所有内存引用都通过自身传递，主要执行**虚拟内存地址到物理地址的转换**。

现代 MMU 通常将虚拟地址空间（处理器使用的地址范围）划分为页面，每个页面的大小为2的幂，通常为几千字节，但它们可能更大。地址的低位（页内的偏移量）保持不变。高地址位是虚拟页号。

## 内核进行内存管理的必要性

为了限制应用访问内存空间的范围并给操作系统提供内存管理的灵活性，计算机硬件需要引入**内存保护/映射/地址转换硬件机制**，如 RISC-V 的基址-边界翻译和保护机制、x86 的分段机制、RISC-V/x86/ARM 都有的分页机制。如果在地址转换过程中，无法找到物理地址或访问权限有误，则处理器产生非法访问内存的异常错误。

## 操作系统与真实内存之间的隔离

为了发挥上述硬件机制的能力，操作系统也需要适配，以便更好地管理物理内存和虚拟内存，并给应用程序提供统一的虚拟内存访问接口。CPU 访问数据和指令的内存地址是虚地址，通过硬件机制（比如 MMU +页表查询）进行地址转换，找到对应的物理地址。**地址空间（Address Space）** 抽象由此产生。在内核中建立虚实地址空间的映射机制，给应用程序提供一个基于地址空间的安全虚拟内存环境，就能让应用程序简单灵活地使用内存。

> - 从应用开发的角度看，需要应用程序决定自己会被加载到哪个物理地址运行，需要直接访问真实的物理内存。这就要求应用开发者对于硬件的特性和使用方法有更多了解，产生额外的学习成本，也会为应用的开发和调试带来不便。
> - 从内核的角度来看，将直接访问物理内存的权力下放到应用会使得它难以对应用程序的访存行为进行有效管理，已有的特权级机制亦无法阻止很多来自应用程序的恶意行为。

应用能够直接看到并访问的内存就只有操作系统提供的地址空间，且**它的任何一次访存使用的地址都是虚拟地址**。应用不再具有直接访问物理内存的能力。应用所处的执行环境在安全方面被进一步强化，形成了用户态特权级和地址空间的二维安全措施。

这样，每个应用独占一个地址空间，里面只含有自己的各个段，它可以随意规划属于它自己的各个段的分布而无需考虑和其他应用冲突；同时鉴于应用只能通过虚拟地址读写它自己的地址空间，它完全无法窃取或者破坏其他应用的数据（不在其地址空间内）。这是地址空间抽象和具体硬件机制对应用程序执行的**安全性**和**稳定性**的一种保障。

![](https://rcore-os.github.io/rCore-Tutorial-Book-v3/_images/address-translation.png)

## MMU与操作系统之间的配合

在 MMU 的帮助下，应用对自己虚拟地址空间的读写被实际转化为对于物理内存的访问。MMU 可能会**将来自不同两个应用地址空间的相同虚拟地址转换成不同的物理地址**。要做到这一点，就需要硬件提供一些寄存器，软件可以对它进行设置来控制 MMU 按照哪个应用的地址映射关系进行地址转换。

**将应用的代码/数据放到物理内存并进行管理，建立好应用的地址映射关系，在任务切换时控制 MMU 选用应用的地址映射关系**，是作为软件部分的内核需要完成的重要工作。

> 内核对于 CPU 资源的抽象——**时分复用**，它为应用制造了一种每个应用独占整个 CPU 的幻象，而隐藏了多个应用分时共享 CPU 的实质。地址空间也是如此，应用只需、也只能看到它独占整个地址空间的幻象，而藏在背后的实质仍然是**多个应用共享物理内存，它们的数据分别存放在内存的不同位置**。

## 现有的地址空间实现策略

地址空间只是一层抽象接口，它有很多种具体的实现策略。对于不同的实现策略来说，操作系统内核如何规划应用数据放在物理内存的位置，而 MMU 又如何进行地址转换也都是不同的。

### 插槽式内存管理

![](https://rcore-os.github.io/rCore-Tutorial-Book-v3/_images/simple-base-bound.png)

每个应用的地址空间大小限制为一个固定的常数 `bound` ，也即每个应用的可用虚拟地址区间均为 $[0,\text{bound})$ 。随后，就可以以这个大小为单位，将物理内存**除了内核预留空间之外的部分**划分为若干个大小相同的 **插槽** (Slot) ，每个应用的所有数据都被内核放置在其中一个插槽中，对应于物理内存上的一段连续物理地址区间，假设其起始物理地址为 base ，则由于二者大小相同，这个区间实际为 $\text{[base,base+bound)}$ 。因此地址转换很容易完成，只需检查一下虚拟地址不超过地址空间的大小限制（借助特权级机制通过异常来进行处理），然后做一个线性映射，将虚拟地址加上 base 就得到了数据实际所在的物理地址。

**好处**：实现极其简单，MMU 只需要 base, bound 两个寄存器，在地址转换进行比较或加法运算即可；内核只需要在任务切换时完成切换 base 寄存器。在对一个应用的内存管理方面，只需考虑一组插槽的占用状态，可以用一个位图来表示，随着应用的新增和退出对应置位或清空。

**不足**：可能浪费的内存资源过多，即固定参数让实现简单，但是不够灵活。

> 注意到应用地址空间预留了一部分，它是用来让栈得以向低地址增长，同时允许堆往高地址增长。每个应用的情况都不同，内核只能按照在它能力范围之内的消耗内存最多的应用的情况来统一指定地址空间的大小，而其他**内存需求较低的应用根本无法充分利用内核给他们分配的这部分空间**。但这部分空间又是一个完整的插槽的一部分，不能再交给其他应用使用。这种在已分配/使用的地址空间内部无法被充分利用的空间就是 **内碎片** (Internal Fragment) ，它限制了系统同时共存的应用数目。如果应用的需求足够多样化，那么内核无论如何设置应用地址空间的大小限制也不能得到满意的结果。

### 分段式内存管理

![](https://rcore-os.github.io/rCore-Tutorial-Book-v3/_images/segmentation.png)

分段式内存管理是以更细的粒度，也就是应用地址空间中的一个逻辑段作为单位来安排应用的数据在物理内存中的布局。

对于每个段来说，从它在某个应用地址空间中的虚拟地址到它被实际存放在内存中的物理地址中间都要经过一个**不同的线性映射**，于是 MMU 需要用一对不同的 base/bound 进行区分。这里由于每个段的大小都是不同的，也不再能仅仅使用一个 bound 进行简化。当任务切换的时候，这些对寄存器也需要被切换。

> 这里忽略一些不必要的细节。比如应用在以虚拟地址为索引访问地址空间的时候，它如何知道该地址属于哪个段，从而硬件可以使用正确的一对 base/bound 寄存器进行合法性检查和完成实际的地址转换。
>
> 这里只关注分段管理是否解决了内碎片带来的内存浪费问题。

**好处**：注意到每个段都只会在内存中占据一块与它实际所用到的大小相等的空间。也就是说这是一种按需分配，而不再是内核在开始时就给每个应用分配一大块很可能用不完的内存。因此，不再有内碎片了。

> 堆的情况可能比较特殊，它的大小可能会在运行时增长，但是那需要应用**通过系统调用向内核请求**。

**不足**：尽管内碎片被消除了，但内存浪费问题并没有完全解决。这是因为每个段的大小都是不同的，内核就需要使用**更加通用、也更加复杂的连续内存分配算法**来进行内存管理，而不能像之前的插槽那样以一个比特为单位。连续内存分配算法就是每次需要分配一块连续内存来存放一个段的数据。随着一段时间的分配和回收，物理内存还剩下一些相互不连续的较小的可用连续块，其中有一些只是两个已分配内存块之间的很小的间隙，它们自己可能由于空间较小，已经无法被用于分配，这就是 **外碎片** (External Fragment) 。

如果这时再想分配一个比较大的块，就需要将这些不连续的外碎片“拼起来”，形成一个大的连续块，然而这涉及到极大的内存读写开销。

### 分页式内存管理

![](https://rcore-os.github.io/rCore-Tutorial-Book-v3/_images/page-table.png)

段的大小不一是外碎片产生的根本原因。若要结合前面两者的优点的话，就需要**内核始终以一个同样大小的单位来在物理内存上放置应用地址空间中的数据**，这样内核就可以使用简单的插槽式内存管理，使得内存分配算法比较简单且不会产生外碎片；同时，这个单位的大小要足够小，从而其内部没有被用到的**内碎片的大小也足够小**，尽可能提高内存利用率。

如图所示，内核以页为单位进行物理内存管理。每个应用的地址空间可以被分成若干个（虚拟） **页面** (Page) ，而可用的物理内存也同样可以被分成若干个（物理） **页帧** (Frame) ，虚拟页面和物理页帧的大小相同。每个虚拟页面中的数据实际上都存储在某个物理页帧上。相比分段内存管理，分页内存管理的粒度更小且大小固定，应用地址空间中的每个逻辑段都由多个虚拟页面组成。而且每个虚拟页面在地址转换的过程中都使用与运行的应用绑定的不同的线性映射。

为了方便实现虚拟页面到物理页帧的地址转换，我们给每个虚拟页面和物理页帧一个编号，分别称为 **虚拟页号** (VPN, Virtual Page Number) 和 **物理页号** (PPN, Physical Page Number) 。每个应用都有一个表示地址映射关系的 **页表** (Page Table) ，里面记录了**该应用地址空间中的每个虚拟页面映射到物理内存中的哪个物理页帧**，即数据实际被内核放在哪里。我们可以用页号来代表二者，因此如果将页表看成一个键值对，其键的类型为虚拟页号，值的类型则为物理页号。当 MMU 进行地址转换的时候，虚拟地址会分为两部分（虚拟页号，页内偏移），MMU首先找到虚拟地址所在虚拟页面的页号，然后查当前应用的页表，根据虚拟页号找到物理页号；最后按照虚拟地址的页内偏移，给物理页号对应的物理页帧的起始地址加上一个偏移量，这就得到了实际访问的物理地址。

在页表中，还针对虚拟页号设置了一组保护位，它限制了**应用对转换得到的物理地址对应的内存的使用方式**，最典型的如 `rwx` 。一旦违反了这种限制则会触发异常，并被内核捕获到。通过适当的设置，可以检查一些应用在运行时的明显错误：比如应用修改只读的代码段，或者从数据段取指令来执行。

**好处**：分页内存管理既简单又灵活，它逐渐成为了主流的内存管理机制，RISC-V 架构也使用了这种机制。

**不足**：页内碎片；动态地址变换、方案实施需耗用额外的系统资源；存储扩充问题没有解决——作业大小受到限制，可用块数小于作业需求时需等待。

## 现有内存管理安全性问题

### Row Hammer 漏洞

2014年，卡内基梅隆大学宣布发现一种存在于动态随机储存器DRAM，也就是现代数字设备使用的内存芯片上的漏洞 Row Hammer。Rowhammer 攻击可以悄悄地破坏 MMU 强制隔离，因为它们根本不需要访问受害者行，并且它们不依赖于隔离机制中的任何设计或实现缺陷。 **Rowhammer 攻击已被证明可以打破所有流行的隔离形式**（如进程内隔离、进程间隔离、内核-用户隔离、虚拟机间隔离和特权用户-访客隔离等）。利用这种漏洞，攻击者可以通过反复加载内存的特定行来实现篡改权限等恶意攻击，无论是运行何种操作程序，PC、手机等几乎所有搭载DRAM内存的X86构架CPU设备都会都会存在安全隐患，这种漏洞被称为RowHammer。随后，内存行业中引入了TRR等手段，认为此漏洞已经被修复。

2020年5月，长期跟踪行业学术与技术发展的联想集团内存研发团队发现，学术界在讨论一种新的威胁，高危的内存漏洞RowHammer没有被完全解决，现有的安全手段可能无法完全阻止利用这个漏洞进行攻击，RowHammer可能死灰复燃：一种新的攻击方法有机会绕过TRR、ECC等内存保护机制进行更有危害的攻击。联想集团内存团队花费半年时间，利用开源工具进行了大量测试，确认在多个供应商提供的元器件中依然存在可利用的RowHammer漏洞。

### CATTmew 漏洞

为了减轻Row Hammer攻击，由 CATT 引入的物理域隔离通过将物理内存划分为多个分区并保持每个分区仅由一个域占用来物理分离每个域。 CATT 将物理内核隔离作为第一个通用且实用的纯软件防御来保护内核免受攻击，因为内核是最吸引人的目标之一。

> 观察到，Row Hammer 攻击本质上需要攻击者控制的内存与特权内存（例如，页表）在物理上相邻，CATT 概念旨在物理分离不同域的内存。
>
> 具体而言，它将物理内存划分为多个分区，并进一步确保分区由至少一个未使用的DRAM行分隔，并且每个分区仅由单个域拥有。例如，用户空间中的堆会从用户分区分配，页表会从内核分区分配。这样做可以将一个域引起的位翻转限制在自己的分区中，从而防止 Row Hammer 攻击影响其他域。

2018年，有人提出一种名为CATTmew的漏洞，声称能够打败纯软件的物理内核隔离。

漏洞利用可以在**不耗尽**页面缓存或系统内存的情况下工作，或者依赖于虚拟到物理地址映射。该漏洞利用的是，现代操作系统具有的双重内核缓冲区（例如，视频缓冲区和 SCSI 通用缓冲区）同时由内核和用户域拥有。这种缓冲区的存在使物理内核隔离失效，并使基于Row Hammer 的攻击再次成为可能。现有的 Row Hammer 攻击实现了 root/内核权限提升，耗尽了页面缓存甚至整个系统内存。他们提出了一种新技术，称为记忆伏击（memory ambush）。它能使可Hammer的双重拥有的内核缓冲区与目标对象（例如，页表）物理上相邻，并且只占用少量内存。

此漏洞本质是**物理内核隔离的内存所有权问题**，即最初为内核分配了一块内核内存，但后来映射到用户空间，允许用户进程访问内核内存，从而避免额外的数据从用户复制到内核，反之亦然。 这种内存所有权的变化使物理内核隔离失效，使内核仍然可以 Hammer。 对于 CATT 概念本身，如果其在实践中的部署没有仔细考虑现代操作系统中的性能优化，那么物理域隔离也是不安全的，因此可能存在类似的内存所有权问题。

> 现代 CPU 采用多级缓存来有效减少内存访问时间。如果数据存在于 CPU 缓存中，则访问它将由缓存完成，并且永远不会到达物理内存。因此，必须刷新 CPU 缓存才能 Row Hammer。

## 

## 参考文献

[CATTmew: Defeating Software-only Physical Kernel Isolation](http://arxiv.org/abs/1802.07060v4)

[Memory management unit From Wikipedia](https://en.wikipedia.org/wiki/Memory_management_unit)

[Operating System - Memory Management](https://www.tutorialspoint.com/operating_system/os_memory_management.htm)

[rCore-Tutorial-Book 第三版](https://rcore-os.github.io/rCore-Tutorial-Book-v3/)

[分页存储管理：分区式存储管理最大的缺点是什么？](https://blog.csdn.net/lingsheng_/article/details/122060450)





